{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train TextCNN\n",
    "Stefan/Yuzhao Heng\n",
    "Since Wed. Mar. 16th. 2022\n",
    "\n",
    "\n",
    "## Setup\n",
    "### Ipython\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Colab\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| PATH_BASE: '/Users/stefanh/Documents/UMich/Research/ECG Classification'\n",
      "    DIR_PROJ: 'ECG-Representation-Learning'\n",
      "    PKG_NM: 'ecg_transformer'\n"
     ]
    },
    {
     "data": {
      "text/plain": "('/Users/stefanh/Documents/UMich/Research/ECG Classification',\n 'ECG-Representation-Learning',\n 'ecg_transformer')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "is_on_colab = 'google.colab' in sys.modules\n",
    "\n",
    "if is_on_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    ! pip3 install sty icecream\n",
    "    ! pip3 install wfdb\n",
    "    ! pip3 install pytorch-lightning transformers datasets\n",
    "    ! pip3 install vit-pytorch\n",
    "\n",
    "    path = os.path.join('drive', 'My Drive', 'Research', 'ECG Classification', 'ECG-Representation-Learning')\n",
    "    sys.path.append(path)\n",
    "    ! ls \"{path}\"\n",
    "\n",
    "    import time, os\n",
    "    os.environ['TZ'] = 'US/Eastern'\n",
    "    time.tzset()\n",
    "\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    ! nvidia-smi\n",
    "\n",
    "\n",
    "from icecream import ic\n",
    "\n",
    "from ecg_transformer.util import *\n",
    "ic(PATH_BASE, DIR_PROJ, PKG_NM)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### code\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 77\n"
     ]
    },
    {
     "data": {
      "text/plain": "77"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from icecream import ic\n",
    "\n",
    "from ecg_transformer.models.train import get_all_setup\n",
    "\n",
    "seed_everything(config('random-seed'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;0;186;142m2022-04-05 19:11:22\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[Get PTB-XL splits]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mget_ptbxl_splits\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mptb_dataset.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m98\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mGetting PTB-XL splits with n=\u001B[34m17792\u001B[39m\u001B[49m\u001B[0m... \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-04-05 19:11:22\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[Get PTB-XL splits]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mget_ptbxl_splits\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mptb_dataset.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m111\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mSplits created with sizes \u001B[35m{\u001B[39m\u001B[49m\u001B[0mtrain: \u001B[34m4\u001B[39m\u001B[49m\u001B[0m, eval: \u001B[34m4\u001B[39m\u001B[49m\u001B[0m, test: \u001B[34m4\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m... \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n"
     ]
    }
   ],
   "source": [
    "# model_size = 'debug'\n",
    "model_size = 'base'\n",
    "t = 'original'\n",
    "\n",
    "# n_sample = 4\n",
    "n_sample = None\n",
    "\n",
    "train_args = dict(\n",
    "    num_train_epoch=64,\n",
    "    train_batch_size=256,\n",
    "    eval_batch_size=256*2,\n",
    "    warmup_ratio=0.1,\n",
    "    n_sample=n_sample,\n",
    "    precision=16,\n",
    "    log_per_epoch=True,\n",
    "    # log_to_console=False\n",
    "    save_while_training=True,\n",
    "    save_every_n_epoch=8,\n",
    "    save_top_k=4\n",
    ")\n",
    "model, trainer = get_all_setup(model_size=model_size, train_args=train_args, ptbxl_type=t)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;0;186;142m2022-04-05 19:11:22\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[EcgVit Train]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m100\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mLaunched training model \u001B[34mEcgVitConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"max_signal_length\": 2560,\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_channels\": 12,\n",
      "  \"num_class\": 12,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"patch_size\": 64,\n",
      "  \"transformers_version\": \"4.17.0\"\n",
      "}\n",
      "\u001B[39m\u001B[49m\u001B[0m with args {\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"num_train_epoch\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m64\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"train_batch_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m256\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"eval_batch_size\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m512\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"learning_rate\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.0003\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"weight_decay\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"warmup_ratio\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m0.1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"n_sample\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m4\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"patience\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m8\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"precision\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m16\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"log_per_epoch\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"log_to_console\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"save_while_training\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34mtrue\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"save_every_n_epoch\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m8\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"save_top_k\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m4\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"steps_per_epoch\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m1\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"n_step\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[34m64\u001B[39;49;00m,\u001B[37m\u001B[39;49;00m\n",
      "\u001B[37m  \u001B[39;49;00m\u001B[94m\"output_dir\"\u001B[39;49;00m:\u001B[37m \u001B[39;49;00m\u001B[33m\"/Users/stefanh/Documents/UMich/Research/ECG Classification/ECG-Representation-Learning/models/2022-04-05_19-11-22\"\u001B[39;49;00m\u001B[37m\u001B[39;49;00m\n",
      "}\u001B[37m\u001B[39;49;00m\n",
      " and \u001B[35m{\u001B[39m\u001B[49m\u001B[0mmodel: \u001B[35m{\u001B[39m\u001B[49m\u001B[0mname: \u001B[34mEcgVit\u001B[39m\u001B[49m\u001B[0m, input shape: \u001B[34m12 x 2560\u001B[39m\u001B[49m\u001B[0m, #patch: \u001B[34m40\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m, #epoch: \u001B[34m64\u001B[39m\u001B[49m\u001B[0m, #step: \u001B[34m64\u001B[39m\u001B[49m\u001B[0m, bsz: \u001B[34m256\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m... \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanh/opt/anaconda3/envs/ecg/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:658: UserWarning: You passed `Trainer(accelerator='cpu', precision=16)` but native AMP is not supported on CPU. Using `precision='bf16'` instead.\n",
      "  rank_zero_warn(\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | EcgVit | 1.8 M \n",
      "---------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.217     Total estimated model params size (MB)\n",
      "/Users/stefanh/opt/anaconda3/envs/ecg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;0;186;142m2022-04-05 19:11:23\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[EcgVit Train]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mlog\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m162\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[35m{\u001B[39m\u001B[49m\u001B[0mepoch: \u001B[34m 0/64\u001B[39m\u001B[49m\u001B[0m, eval/loss: \u001B[34m0.7326\u001B[39m\u001B[49m\u001B[0m, eval/binary_accuracy: \u001B[34m48.94\u001B[39m\u001B[49m\u001B[0m, eval/weighted_binary_accuracy: \u001B[34m52.14\u001B[39m\u001B[49m\u001B[0m, eval/binary_negative_recall: \u001B[34m 3.42\u001B[39m\u001B[49m\u001B[0m, eval/binary_positive_recall: \u001B[34m 97.1\u001B[39m\u001B[49m\u001B[0m, eval/macro_auc: \u001B[34m29.17\u001B[39m\u001B[49m\u001B[0m, eval/per_class_auc: \u001B[35m{\u001B[39m\u001B[49m\u001B[0mNORM: \u001B[34m  0.00\u001B[39m\u001B[49m\u001B[0m, IMI: \u001B[34m100.00\u001B[39m\u001B[49m\u001B[0m, ABQRS: \u001B[34m 25.00\u001B[39m\u001B[49m\u001B[0m, SR: \u001B[34m 50.00\u001B[39m\u001B[49m\u001B[0m, AFIB: \u001B[34m  0.00\u001B[39m\u001B[49m\u001B[0m, AFLT: \u001B[34m  0.00\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 77\n",
      "/Users/stefanh/opt/anaconda3/envs/ecg/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;2;0;186;142m2022-04-05 19:11:24\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[EcgVit Train]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mlog\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m162\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[35m{\u001B[39m\u001B[49m\u001B[0mepoch: \u001B[34m 1/64\u001B[39m\u001B[49m\u001B[0m, step: \u001B[34m 1/64\u001B[39m\u001B[49m\u001B[0m, train/learning_rate: \u001B[34m0.000e+00\u001B[39m\u001B[49m\u001B[0m, train/loss: \u001B[34m0.7439\u001B[39m\u001B[49m\u001B[0m, train/binary_accuracy: \u001B[34m47.54\u001B[39m\u001B[49m\u001B[0m, train/weighted_binary_accuracy: \u001B[34m46.04\u001B[39m\u001B[49m\u001B[0m, train/binary_negative_recall: \u001B[34m  2.7\u001B[39m\u001B[49m\u001B[0m, train/binary_positive_recall: \u001B[34m96.32\u001B[39m\u001B[49m\u001B[0m, train/macro_auc: \u001B[34m-\u001B[39m\u001B[49m\u001B[0m, train/per_class_auc: \u001B[35m{\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-04-05 19:11:26\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[EcgVit Train]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mlog\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m162\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[35m{\u001B[39m\u001B[49m\u001B[0mepoch: \u001B[34m 1/64\u001B[39m\u001B[49m\u001B[0m, eval/loss: \u001B[34m0.7326\u001B[39m\u001B[49m\u001B[0m, eval/binary_accuracy: \u001B[34m48.94\u001B[39m\u001B[49m\u001B[0m, eval/weighted_binary_accuracy: \u001B[34m52.14\u001B[39m\u001B[49m\u001B[0m, eval/binary_negative_recall: \u001B[34m 3.42\u001B[39m\u001B[49m\u001B[0m, eval/binary_positive_recall: \u001B[34m 97.1\u001B[39m\u001B[49m\u001B[0m, eval/macro_auc: \u001B[34m29.17\u001B[39m\u001B[49m\u001B[0m, eval/per_class_auc: \u001B[35m{\u001B[39m\u001B[49m\u001B[0mNORM: \u001B[34m  0.00\u001B[39m\u001B[49m\u001B[0m, IMI: \u001B[34m100.00\u001B[39m\u001B[49m\u001B[0m, ABQRS: \u001B[34m 25.00\u001B[39m\u001B[49m\u001B[0m, SR: \u001B[34m 50.00\u001B[39m\u001B[49m\u001B[0m, AFIB: \u001B[34m  0.00\u001B[39m\u001B[49m\u001B[0m, AFLT: \u001B[34m  0.00\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-04-05 19:11:27\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[EcgVit Train]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mlog\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m162\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[35m{\u001B[39m\u001B[49m\u001B[0mepoch: \u001B[34m 2/64\u001B[39m\u001B[49m\u001B[0m, step: \u001B[34m 2/64\u001B[39m\u001B[49m\u001B[0m, train/learning_rate: \u001B[34m5.000e-05\u001B[39m\u001B[49m\u001B[0m, train/loss: \u001B[34m0.7284\u001B[39m\u001B[49m\u001B[0m, train/binary_accuracy: \u001B[34m 50.7\u001B[39m\u001B[49m\u001B[0m, train/weighted_binary_accuracy: \u001B[34m53.05\u001B[39m\u001B[49m\u001B[0m, train/binary_negative_recall: \u001B[34m 3.55\u001B[39m\u001B[49m\u001B[0m, train/binary_positive_recall: \u001B[34m 97.2\u001B[39m\u001B[49m\u001B[0m, train/macro_auc: \u001B[34m-\u001B[39m\u001B[49m\u001B[0m, train/per_class_auc: \u001B[35m{\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-04-05 19:11:29\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[EcgVit Train]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mlog\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m162\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[35m{\u001B[39m\u001B[49m\u001B[0mepoch: \u001B[34m 2/64\u001B[39m\u001B[49m\u001B[0m, eval/loss: \u001B[34m0.7267\u001B[39m\u001B[49m\u001B[0m, eval/binary_accuracy: \u001B[34m48.59\u001B[39m\u001B[49m\u001B[0m, eval/weighted_binary_accuracy: \u001B[34m46.59\u001B[39m\u001B[49m\u001B[0m, eval/binary_negative_recall: \u001B[34m 2.76\u001B[39m\u001B[49m\u001B[0m, eval/binary_positive_recall: \u001B[34m 96.4\u001B[39m\u001B[49m\u001B[0m, eval/macro_auc: \u001B[34m33.33\u001B[39m\u001B[49m\u001B[0m, eval/per_class_auc: \u001B[35m{\u001B[39m\u001B[49m\u001B[0mNORM: \u001B[34m  0.00\u001B[39m\u001B[49m\u001B[0m, IMI: \u001B[34m100.00\u001B[39m\u001B[49m\u001B[0m, ABQRS: \u001B[34m 50.00\u001B[39m\u001B[49m\u001B[0m, SR: \u001B[34m 50.00\u001B[39m\u001B[49m\u001B[0m, AFIB: \u001B[34m  0.00\u001B[39m\u001B[49m\u001B[0m, AFLT: \u001B[34m  0.00\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n",
      "\u001B[38;2;0;186;142m2022-04-05 19:11:31\u001B[38;2;97;175;239m| \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;198;120;221m[EcgVit Train]\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mlog\u001B[38;2;97;175;239m::\u001B[38;2;198;120;221mtrain.py\u001B[38;2;97;175;239m:\u001B[38;2;198;120;221m162\u001B[38;2;97;175;239m, \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29mINFO\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[38;2;97;175;239m - \u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\u001B[35m{\u001B[39m\u001B[49m\u001B[0mepoch: \u001B[34m 3/64\u001B[39m\u001B[49m\u001B[0m, step: \u001B[34m 3/64\u001B[39m\u001B[49m\u001B[0m, train/learning_rate: \u001B[34m1.000e-04\u001B[39m\u001B[49m\u001B[0m, train/loss: \u001B[34m0.7272\u001B[39m\u001B[49m\u001B[0m, train/binary_accuracy: \u001B[34m51.06\u001B[39m\u001B[49m\u001B[0m, train/weighted_binary_accuracy: \u001B[34m53.23\u001B[39m\u001B[49m\u001B[0m, train/binary_negative_recall: \u001B[34m 3.57\u001B[39m\u001B[49m\u001B[0m, train/binary_positive_recall: \u001B[34m97.22\u001B[39m\u001B[49m\u001B[0m, train/macro_auc: \u001B[34m-\u001B[39m\u001B[49m\u001B[0m, train/per_class_auc: \u001B[35m{\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[35m}\u001B[39m\u001B[49m\u001B[0m\u001B[39m\u001B[49m\u001B[22m\u001B[23m\u001B[24m\u001B[25m\u001B[27m\u001B[28m\u001B[29m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanh/opt/anaconda3/envs/ecg/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}